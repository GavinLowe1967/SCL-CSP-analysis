\subsection{Closing channels}

\inlineScala

We now consider the closing of channels.  Recall that, after the channel has
been closed, a |send| or |receive| invocation fails and throws a |Closed|
exception.

Implementing the |close| operation correctly proved harder than expected.  An
earlier version of the implementation suffered from a bug involving three
threads acting concurrently: thread~$A$ calls |send(x)|, thread~$B$ calls
|receive|, and thread~$C$ calls |close|.  Under certain conditions, it was
possible for thread~$B$ to return successfully, having received~|x|, but for
thread~$A$ to see the channel closed, and so throw a |Closed| exception.  We
consider this behaviour to be incorrect: either both~$A$ and~$B$ should think
the communication has succeeded, or both should throw |Closed| exceptions.

%%%%%%%%%% Implementation

The implementation uses a boolean variable |isChanClosed| that records whether
the channel is closed.  The |close| operation sets this variable, and signals
to all the threads waiting on conditions.

When a thread calls |send| or |receive|, if |isChanClosed| is set, it throws a
|Closed| exception.  Likewise, if a sending thread waits on |slotEmptied|, it
performs a similar check when it receives a signal.  

If a receiving thread waits on |slotFull|, when it receives a signal, it first
checks whether |status| holds |Filled|.  If so, it continues as described
earlier: thus we prioritise completing the communication over checking whether
the channel has been closed (this seems necessary for correct interaction with
alts).
%% More precisely, an alt might have filled the slot, which implies it has
%% performed the computation to calculate the value: at this point, it is
%% committed to the communication. 
If |status| does not hold |Filled|, the thread checks whether the channel has
been closed, and if so throws an exception; otherwise, it waits again on
|slotFull|.

If a sending thread waits on |continue|, when it receives a signal, it 
first checks whether |status| holds |Read|, and if so continues as described
earlier.  Otherwise, it must be the case that |isChanClosed| has been set (the
implementation asserts this, and the analysis below checks this).  However, if
there is a receiver waiting (as recorded by |receiversWaiting|), then that
receiver will eventually return the value being sent, so the sending thread
should also return successfully.  If there is no waiting receiver, the sending
thread throws a |Closed| exception.  

The precise order of checks in the previous paragraph is rather subtle.  This
is where the earlier implementation went wrong.  Previously, when the waiting
thread received a signal, it first checked |isChanClosed|, and if it was set,
threw a |Closed| exception.  This could be wrong, as a receiving thread might
have read the sending thread's value, and returned that value, indicating that
it had correctly synchronised.  The correct version of the code was found with
the help of the model checking described below. 

%%%%%%%%%% Model

\inlineCSP

Adapting the CSP model to model closing of channels is straightforward.  The
|endSend| and |endReceive| channels are extended to allow a result |Closed|,
corresponding to the \SCALA{Closed} exception.  The \SCALA{close} operation is
modelled as for earlier operations, framed by events on channels |beginClose|
and |endClosed|.

%%%%%%%%%% Testing

To analyse this extended model, we adapt the |System| process from earlier to
also allow threads to close channels.  

The channel specification in Section~\ref{sec:syncchan-analysis-1} is (in the
terminology of~\cite{LL:synchronisation}) \emph{stateless}: no state is
carried forward from one synchronisation to another.  However, when we
consider closing of the channel, it becomes \emph{stateful}, with two states,
open or closed.  (Other synchronisation objects have more interesting states.)

Our specification will treat \SCALA{close} as a linearisable operation: it
will appear to take place atomically, at some point, called the
\emph{linearisation point}, between the |beginClose| and |endClose| events.
(Equivalently, the |close| operation can be thought of as a unary
synchronisation, involving a single thread, in contrast to the earlier binary
synchronisations.)  We require that the history is consistent with this
closing: synchronisations between sends and receives should take place before
the linearisation point of the close; and sends and receives that return
|Closed| should be linearised after the close.

We use a CSP event |close.t| to represent the linearisation point of a
\SCALA{close} operation by thread~|t|.  Further, we use an event |closed.t| to
represent the linearisation point of a send or receive operation by thread~|t|
that returns |Closed| because it finds the channel is closed.

Within the specification, the state of the channel is recorded by the process
|ChanSpec|.  When the channel is open, it allows threads to synchronise, or
allows a thread to close the channel.  When the channel is closed, it allows
linearisation points of sends or receives that return |Closed|, or allows the
linearisation point of another |close| operation (a |close| operation on a
channel that is already closed has no effect).
%
\begin{cspm}
ChanSpec = sync?t1?t2?x -> ChanSpec [] close?t -> ChanSpecClosed
ChanSpecClosed = isClosed?t -> ChanSpecClosed [] close?t -> ChanSpecClosed
alphaChanSpec = {|sync, close, isClosed|} 
\end{cspm}

We adapt the lineariser processes to reflect the closing of channels.  A
sending thread can either synchronise with another thread, as before, or find
the channel is closed and so return the |Closed| value.  (The |SendingLin|
process that describes this is parameterised by the corresponding |endSend|
channel, to facilitate extension to the timed operations later.)  Receiving is
treated similarly.  Further, the linearisation point for a \SCALA{close}
operation can take place between |beginClose| and |endClose| events.
%
%\pagebreak[1]
%\begin{mysamepage}
\begin{cspm}
Lin(t) = 
  C::beginSend.t?x -> SendingLin(t, x, C::endSend.t)
  [] C::beginReceive.t -> ReceivingLin(t, C::endReceive.t)
  [] C::beginClose.t -> close.t -> C::endClose.t -> Lin(t)

SendingLin(t, x, endChan) = 
  sync.t?other!x -> endChan.SendSuccess -> Lin(t)
  [] isClosed.t -> endChan.Closed -> Lin(t)

ReceivingLin(t, endChan) =  
  sync?other!t?x -> endChan.ReceiveSuccess.x -> Lin(t)
  [] isClosed.t -> endChan.Closed -> Lin(t)
\end{cspm}
%\end{mysamepage}

We combine the linearisers as before (with suitably extended alphabets).  We
then synchronise them with |ChanSpec| on the relevant events, and hide those
events.
%
\begin{cspm}
Spec£$_0$£ = **|| t <- ThreadID @ [alphaLin(t)] Lin(t)
Spec = (Spec£$_0$£ [| alphaChanSpec |] ChanSpec) \ alphaChanSpec
\end{cspm}
%
Thus |Spec| allows all traces, containing the |begin| and |end| events, that
are synchronisation linearisable.  So testing \CSPM{Spec [T= System}
%] bracket match hack
verifies synchronisation linearisability for this system.  Performing the
corresponding test in the stable failures model also verifies synchronisation
progressibility.  Finally, performing the test in the failures-divergences
model also verifies that all assertions in the code pass, and that threads
cannot perform an infinite amount of internal activity without a thread
returning.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsection{Timed operations}
\label{sec:syncchan-timed}

\inlineScala

We now consider the timed send and receive operations on channels.  

The SCL conditions described earlier provide a timed wait operation: the
thread waits until either it receives a signal, or the time is elapsed; the
operation returns a boolean indicating whether a signal was received.  The
timed send and receive operations are based around this. 

The |sendWithin(duration)(x)| operation initially waits on |slotEmptied| until
either |status| holds |Empty| or the channel is closed (which it rechecks when
it receives a signal), or the deadline is reached.  If the channel is closed,
it throws a |Closed| exception.  If it timedout, it returns |false|.
Otherwise, it continues as in the untimed operation, except it waits on
|continue| until at most |duration| after the initial call.  If it then finds
that |status| is |Read|, then the send has been successful; it continues as in
the untimed operation, and returns |true|.  Otherwise |status| must still hold
|Filled| and |value| must stll hold~|x| (the implementation asserts this, and
the analysis below checks this).  If the channel is closed, it continues as in
the untimed operation.  Otherwise, it must have timedout, so it sets |status|
to |Empty| to clear its value, signals to any thread waiting on |slotEmptied|,
and returns |false|.

The |receiveWithin(duration)| operation acts much as the untimed version,
except it waits on |slotFull| until at most |duration| after the initial
call.  If it then finds that |status| holds |Filled|, it continues as in the
untimed case, returning a suitable |Some| value.  If the channel is closed, it
throws a |Closed| exception.  Otherwise it must have timedout, so returns
|None|.  

%%%%% Modelling

We now describe the CSP model of these operations.  Our analysis does not
consider absolute time; thus we abstract away from the duration of a timed
send or receive.  The difficult part of the implementation is getting the
synchronisations right, rather than the length of the delay. 

The CSP model of an SCL monitor also models timed waits.  It records which
threads are doing timed waits on which conditions.  Such threads can receive a
signal, as for untimed waits.  In addition, they can time out, and
subsequently acquire the lock on the monitor.  Thus we model that such threads
can eventually time out, but don't model the length of the delay.

The |sendWithin| and |receiveWithin| operations can then be modelled in CSP
much as before, using these timed waits.


%%%%% Analysis

\inlineCSP

We adapt the specification of synchronisation linearisability as follows.  We
introduce events |timeout.t| to represent the linearisation point of a
\SCALA{sendWithin} or \SCALA{receiveWithin} operation by thread~|t| that times
out.  We then adapt the definition of the lineariser processes for these
operations as follows, adding the possibility of such a time out to the
possibilities of the untimed operations.
%
\begin{cspm}
Lin(me) = 
  ... -- as before
  [] C::beginSendWithin.me?x -> SendingWithinLin(me, x, C::endSendWithin.me)
  [] C::beginReceiveWithin.me -> ReceivingWithinLin(me, C::endReceiveWithin.me)

SendingWithinLin(me, x, endChan) = 
  SendingLin(me, x, endChan)
  [] timeout.me -> endChan.Timeout -> Lin(me)

ReceivingWithinLin(me, endChan) = 
  ReceivingLin(me, endChan) 
  [] timeout.me -> endChan.Timeout -> Lin(me)
\end{cspm}
%
Further, we adapt the |ChanSpec| process to allow |timeout| events only before
the channel is closed.  The rest of the construction and checks are then as
before. 

\begin{window}[2,r,{
%
\vspace{0.5ex}
\begin{tabular}[b]{\|cccc\|}
Model & Threads & States  & Time\\
FD & 3  & 1.23M & 3.6s\\
FD & 4 & 92.5M  & 43s \\
F & 5 & 7.22B & 34min 
\end{tabular}
%\vspace{1ex}
},]
%
The table to the right gives statistics about the number of states explored
and the times taken to perform these checks, in different models, and for
different numbers of threads.  Each test used two data values (and this is the
case for all later checks reported in this paper).  All
experiments in this paper were performed on a 32-core server (two 2.1GHz
Intel(R) Xeon(R) Gold 6130 CPUs with hyperthreading enabled, with 512GB of
RAM).  The check with 5 threads in the failures-divergences model was beyond
the limits of this machine.  As is normally the case, the state space, and
hence the checking time, grows rapidly with the number of threads.   
\end{window}


It is worth mentioning an alternative approach, which turns out not to work in
this case.  For standard concurrent datatypes, linearisability is often
verified by identifying \emph{linearisation points}: specific points in the
program code where an invocation appears to take place.  By analogy, can we
identify \emph{synchronisation points} in the program code for each operation,
where the thread is aware of the result of the invocation, and then capture
the correctness condition in terms of these synchronisation points?  This idea
won't work in this case, for the following reason.  The synchronisation point
for the sending thread would have to be after it receives the signal on
\SCALA{continue} and regains the lock, because it doesn't know the result of
the synchronisation before this; but this might be too late, because the
channel might have been closed before it obtained the lock, and so the
synchronisation would appear incorrect.
